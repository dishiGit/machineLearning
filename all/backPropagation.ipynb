{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#import opencv as cv2\n",
    "\n",
    "img_array = np.load('test_images.npy',encoding='latin1')\n",
    "\n",
    "images = np.load('train_images.npy',encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "def readCSV(path):\n",
    "    with open(path) as csv_file:\n",
    "        result = []\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            line = []\n",
    "            for data in row:\n",
    "                line.append(data)\n",
    "            result.append(line)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input=[]\n",
    "for i in range(len(images)):\n",
    "    image1 = (images[i][1]).reshape(100,100)\n",
    "    #plt.imshow(image1)\n",
    "    img = cv2.imwrite('temp.jpg',image1)\n",
    "    img = cv2.imread('temp.jpg',0)\n",
    "    edges = cv2.Canny(img, 0, 100)\n",
    "    #plt.imshow(edges)\n",
    "\n",
    "    im2, contours, hierarchy = cv2.findContours(edges, cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = sorted(contours, key = cv2.contourArea, reverse = True)[:3]\n",
    "\n",
    "\n",
    "    mask=np.zeros(img.shape)\n",
    "    cv2.drawContours(mask, cnts, -1, (255),1)\n",
    "    input.append(mask)\n",
    "    #plt.imshow(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "print(img_array[1][1])\n",
    "labels = np.array(readCSV('train_labels.csv'))#np.loadtxt('train_labels.csv',dtype=str,delimiter=',')\n",
    "# X = [x.yeshape(10000,) for x in input]\n",
    "X = [y for x,y in img_array]\n",
    "y = labels[1:,1].tolist()\n",
    "\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}\n"
     ]
    }
   ],
   "source": [
    "#convert classes from text to interger\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y_encoded = encoder.transform(y)\n",
    "print(set(y_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "# max-polling\n",
    "import numpy as np\n",
    "import skimage.measure\n",
    "x = [skimage.measure.block_reduce(a, (4,4), np.max) for a in input]\n",
    "print(len(x[0]))\n",
    "X = [a.reshape(625,) for a in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25]\n"
     ]
    }
   ],
   "source": [
    "#combine x and y and nomarlize input\n",
    "train = []\n",
    "for i in range(len(X)):\n",
    "    a = []\n",
    "    for k in X[i]:\n",
    "        a.append(k/255)\n",
    "    a.append(y_encoded[i])\n",
    "    train.append(a)\n",
    "print(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of hidden units: 1\n",
      "Accuracy achieced in fold 1: 0.057731\n",
      "Accuracy achieced in fold 2: 0.069807\n",
      "Accuracy achieced in fold 3: 0.087290\n",
      "Accuracy achieced in fold 4: 0.098175\n",
      "Accuracy achieced in fold 5: 0.086958\n",
      "Mean Accuracy: 0.079992 \n",
      "\n",
      "num of hidden units: 10\n",
      "Accuracy achieced in fold 1: 0.187283\n",
      "Accuracy achieced in fold 2: 0.164231\n",
      "Accuracy achieced in fold 3: 0.158467\n",
      "Accuracy achieced in fold 4: 0.115100\n",
      "Accuracy achieced in fold 5: 0.158327\n",
      "Mean Accuracy: 0.156681 \n",
      "\n",
      "num of hidden units: 100\n",
      "Accuracy achieced in fold 1: 0.429432\n",
      "Accuracy achieced in fold 2: 0.418966\n",
      "Accuracy achieced in fold 3: 0.420663\n",
      "Accuracy achieced in fold 4: 0.418145\n",
      "Accuracy achieced in fold 5: 0.419236\n",
      "Mean Accuracy: 0.421288 \n",
      "\n",
      "num of hidden units: 200\n",
      "Accuracy achieced in fold 1: 0.446459\n",
      "Accuracy achieced in fold 2: 0.465721\n",
      "Accuracy achieced in fold 3: 0.479074\n",
      "Accuracy achieced in fold 4: 0.470968\n",
      "Accuracy achieced in fold 5: 0.435660\n",
      "Mean Accuracy: 0.459576 \n",
      "\n",
      "num of hidden units: 250\n",
      "Accuracy achieced in fold 1: 0.441994\n",
      "Accuracy achieced in fold 2: 0.457938\n",
      "Accuracy achieced in fold 3: 0.467119\n",
      "Accuracy achieced in fold 4: 0.442880\n",
      "Accuracy achieced in fold 5: 0.434065\n",
      "Mean Accuracy: 0.448799 \n",
      "\n",
      "num of hidden units: 300\n",
      "Accuracy achieced in fold 1: 0.534228\n",
      "Accuracy achieced in fold 2: 0.518627\n",
      "Accuracy achieced in fold 3: 0.538222\n",
      "Accuracy achieced in fold 4: 0.515270\n",
      "Accuracy achieced in fold 5: 0.517069\n",
      "Mean Accuracy: 0.524683 \n",
      "\n",
      "num of hidden units: 350\n",
      "Accuracy achieced in fold 1: 0.453813\n",
      "Accuracy achieced in fold 2: 0.482878\n",
      "Accuracy achieced in fold 3: 0.521424\n",
      "Accuracy achieced in fold 4: 0.510745\n",
      "Accuracy achieced in fold 5: 0.465217\n",
      "Mean Accuracy: 0.486815 \n",
      "\n",
      "num of hidden units: 400\n",
      "Accuracy achieced in fold 1: 0.529157\n",
      "Accuracy achieced in fold 2: 0.540686\n",
      "Accuracy achieced in fold 3: 0.539541\n",
      "Accuracy achieced in fold 4: 0.527095\n",
      "Accuracy achieced in fold 5: 0.520260\n",
      "Mean Accuracy: 0.531348 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Backprop on the Seeds Dataset\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from random import random\n",
    "from math import exp\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    iteration = 0    \n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        print(\"Accuracy in fold %d: %f\" % (iteration, accuracy))        \n",
    "        scores.append(accuracy)\n",
    "        iteration += 1\n",
    "    return scores\n",
    "\n",
    "# Calculate pre-activation for an input\n",
    "def preactivate(weights, inputs):\n",
    "    preactivation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        preactivation += weights[i] * inputs[i]\n",
    "    return preactivation\n",
    "\n",
    "# Transfer neuron activation using sigmoid function\n",
    "def activate(preactivation):\n",
    "    return 1.0 / (1.0 + exp(-preactivation))\n",
    "\n",
    "# Forward propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            preactivation = preactivate(neuron['weights'], inputs)\n",
    "            neuron['output'] = activate(preactivation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs\n",
    "\n",
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "    for i in range(len(network)):\n",
    "        outputs = row[:-1]\n",
    "        if i != 0:\n",
    "            outputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(outputs)):\n",
    "                neuron['weights'][j] += l_rate * neuron['delta'] * outputs[j]\n",
    "            neuron['weights'][-1] += l_rate * neuron['delta']\n",
    "\n",
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "# \t\tprint(\"error: %f\" % sum_error)\n",
    "\n",
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    "\n",
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "    outputs = forward_propagate(network, row)\n",
    "    return outputs.index(max(outputs))\n",
    "\n",
    "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
    "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
    "    n_inputs = len(train[0]) - 1\n",
    "    n_outputs = len(set([row[-1] for row in train]))\n",
    "    network = initialize_network(n_inputs, n_hidden, n_outputs)\n",
    "    train_network(network, train, l_rate, n_epoch, n_outputs)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = predict(network, row)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)\n",
    "\n",
    "n_folds = 5\n",
    "l_rate = 0.001\n",
    "n_epoch = 300\n",
    "# n_hidden = 100\n",
    "n_hidden = [1,10,100,200,250,300,350,400]\n",
    "for hidden in n_hidden:\n",
    "    print('num of hidden units: %d' % hidden)\n",
    "    acc = evaluate_algorithm(train, back_propagation, n_folds, l_rate, n_epoch, hidden)\n",
    "    print('Mean Accuracy: %f' % (sum(acc)/float(len(acc))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
