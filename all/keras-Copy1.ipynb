{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten, AlphaDropout, SpatialDropout2D, Cropping2D\n",
    "from keras.constraints import maxnorm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "np.set_printoptions(threshold=20000)\n",
    "\n",
    "# load data\n",
    "image_data='train_images.npy'\n",
    "label_data='train_labels.csv'\n",
    "\n",
    "# images = np.load(image_data, encoding='latin1')\n",
    "images = np.load(image_data, encoding='latin1')[:,1]\n",
    "labels = np.loadtxt(label_data, dtype=str, encoding='latin1', delimiter=',')[1:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=[]\n",
    "# for i in range(len(images)):\n",
    "#     image1 = (images[i][1]).reshape(100,100)\n",
    "#     #plt.imshow(image1)\n",
    "#     img = cv2.imwrite('temp.jpg',image1)\n",
    "#     img = cv2.imread('temp.jpg',0)\n",
    "#     edges = cv2.Canny(img, 0, 100)\n",
    "#     #plt.imshow(edges)\n",
    "\n",
    "#     im2, contours, hierarchy = cv2.findContours(edges, cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     cnts = sorted(contours, key = cv2.contourArea, reverse = True)[:1]\n",
    "\n",
    "\n",
    "#     mask=np.zeros(img.shape, np.uint8)\n",
    "#     cv2.drawContours(mask, cnts, -1, (255),1)\n",
    "#     a.append(mask)\n",
    "#     #plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to \"2d\" form\n",
    "# print(images[0])\n",
    "# print(images.shape)\n",
    "X = np.reshape(images.tolist(), (-1,100,100,1))\n",
    "X = X.astype('float32')/255\n",
    "\n",
    "\n",
    "# one-hot encoding for y\n",
    "encoder=LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "y_encoded = encoder.transform(labels)\n",
    "y = keras.utils.to_categorical(y_encoded)\n",
    "\n",
    "# shuffle(X,y)\n",
    "# X = X[:1000]\n",
    "# y = y[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cropping2d_1 (Cropping2D)    (None, 96, 96, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 16)        800       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 48, 48, 16)        6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 16)          4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 16)          1040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 31)                4495      \n",
      "=================================================================\n",
      "Total params: 22,015\n",
      "Trainable params: 22,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Cropping2D(2, input_shape=(100,100,1)))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Conv2D(16, 7, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(16, 5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "# model.add(Conv2D(8, 3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(16, 5, padding='same', activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv2D(16, 5, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(32, 5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=4))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Conv2D(16, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Dropout(0.05))\n",
    "model.add(Conv2D(16, 2, padding='same', activation='relu'))\n",
    "\n",
    "# model.add(MaxPooling2D(pool_size=2))\n",
    "# model.add(Conv2D(32, 2, padding='same', activation='relu'))\n",
    "\n",
    "# model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "\n",
    "\n",
    "# # model.add(Conv2D(128, 7, padding='same', activation='relu'))\n",
    "# # model.add(Conv2D(128, 7, padding='same', activation='relu'))\n",
    "\n",
    "# # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(64, 5, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 5, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 5, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "# # model.add(Conv2D(128, 3, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "# # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "# model.add(Conv2D(64, 2, padding='same', activation='relu'))\n",
    "\n",
    "# model.add(Conv2D(256, 2, padding='same', activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(31, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/60\n",
      "8000/8000 [==============================] - 6s 695us/step - loss: 3.3908 - acc: 0.0545 - val_loss: 3.3833 - val_acc: 0.0575\n",
      "Epoch 2/60\n",
      "8000/8000 [==============================] - 4s 472us/step - loss: 3.1972 - acc: 0.0808 - val_loss: 3.0361 - val_acc: 0.0985\n",
      "Epoch 3/60\n",
      "8000/8000 [==============================] - 4s 463us/step - loss: 2.9405 - acc: 0.1355 - val_loss: 2.8104 - val_acc: 0.1835\n",
      "Epoch 4/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 2.7269 - acc: 0.1921 - val_loss: 2.6188 - val_acc: 0.2170\n",
      "Epoch 5/60\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 2.4841 - acc: 0.2641 - val_loss: 2.3540 - val_acc: 0.2960\n",
      "Epoch 6/60\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 2.2804 - acc: 0.3133 - val_loss: 2.3083 - val_acc: 0.2990\n",
      "Epoch 7/60\n",
      "8000/8000 [==============================] - 4s 450us/step - loss: 2.1658 - acc: 0.3521 - val_loss: 2.1438 - val_acc: 0.3580\n",
      "Epoch 8/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 2.0611 - acc: 0.3754 - val_loss: 2.1632 - val_acc: 0.3430\n",
      "Epoch 9/60\n",
      "8000/8000 [==============================] - 4s 450us/step - loss: 1.9854 - acc: 0.4037 - val_loss: 2.0209 - val_acc: 0.4170\n",
      "Epoch 10/60\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 1.9069 - acc: 0.4291 - val_loss: 2.0477 - val_acc: 0.3910\n",
      "Epoch 11/60\n",
      "8000/8000 [==============================] - 4s 448us/step - loss: 1.8623 - acc: 0.4408 - val_loss: 2.0347 - val_acc: 0.3830\n",
      "Epoch 12/60\n",
      "8000/8000 [==============================] - 4s 448us/step - loss: 1.7954 - acc: 0.4522 - val_loss: 1.8576 - val_acc: 0.4535\n",
      "Epoch 13/60\n",
      "8000/8000 [==============================] - 4s 448us/step - loss: 1.7406 - acc: 0.4779 - val_loss: 1.8365 - val_acc: 0.4530\n",
      "Epoch 14/60\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 1.6971 - acc: 0.4960 - val_loss: 1.8801 - val_acc: 0.4420\n",
      "Epoch 15/60\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 1.6736 - acc: 0.4936 - val_loss: 1.8252 - val_acc: 0.4670\n",
      "Epoch 16/60\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 1.6302 - acc: 0.5130 - val_loss: 1.7622 - val_acc: 0.4665\n",
      "Epoch 17/60\n",
      "8000/8000 [==============================] - 4s 448us/step - loss: 1.5931 - acc: 0.5181 - val_loss: 1.7910 - val_acc: 0.4675\n",
      "Epoch 18/60\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 1.5760 - acc: 0.5172 - val_loss: 1.7325 - val_acc: 0.4870\n",
      "Epoch 19/60\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 1.5465 - acc: 0.5320 - val_loss: 1.7878 - val_acc: 0.4740\n",
      "Epoch 20/60\n",
      "8000/8000 [==============================] - 4s 453us/step - loss: 1.5231 - acc: 0.5366 - val_loss: 1.7197 - val_acc: 0.4930\n",
      "Epoch 21/60\n",
      "8000/8000 [==============================] - 4s 450us/step - loss: 1.4762 - acc: 0.5559 - val_loss: 1.7317 - val_acc: 0.4885\n",
      "Epoch 22/60\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 1.4655 - acc: 0.5520 - val_loss: 1.7015 - val_acc: 0.5070\n",
      "Epoch 23/60\n",
      "8000/8000 [==============================] - 4s 450us/step - loss: 1.4415 - acc: 0.5664 - val_loss: 1.6992 - val_acc: 0.4970\n",
      "Epoch 24/60\n",
      "8000/8000 [==============================] - 4s 454us/step - loss: 1.4334 - acc: 0.5607 - val_loss: 1.6592 - val_acc: 0.5295\n",
      "Epoch 25/60\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 1.4306 - acc: 0.5660 - val_loss: 1.6890 - val_acc: 0.5045\n",
      "Epoch 26/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 1.4112 - acc: 0.5673 - val_loss: 1.6625 - val_acc: 0.5320\n",
      "Epoch 27/60\n",
      "8000/8000 [==============================] - 4s 450us/step - loss: 1.3863 - acc: 0.5831 - val_loss: 1.7007 - val_acc: 0.5205\n",
      "Epoch 28/60\n",
      "8000/8000 [==============================] - 4s 453us/step - loss: 1.3620 - acc: 0.5855 - val_loss: 1.6525 - val_acc: 0.5285\n",
      "Epoch 29/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 1.3696 - acc: 0.5841 - val_loss: 1.6470 - val_acc: 0.5280\n",
      "Epoch 30/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 1.3612 - acc: 0.5785 - val_loss: 1.6914 - val_acc: 0.5335\n",
      "Epoch 31/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 1.3585 - acc: 0.5847 - val_loss: 1.6378 - val_acc: 0.5400\n",
      "Epoch 32/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 1.3295 - acc: 0.5921 - val_loss: 1.5923 - val_acc: 0.5565\n",
      "Epoch 33/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 1.3189 - acc: 0.6021 - val_loss: 1.6584 - val_acc: 0.5320\n",
      "Epoch 34/60\n",
      "8000/8000 [==============================] - 4s 450us/step - loss: 1.3129 - acc: 0.5955 - val_loss: 1.6023 - val_acc: 0.5405\n",
      "Epoch 35/60\n",
      "8000/8000 [==============================] - 4s 453us/step - loss: 1.3189 - acc: 0.5980 - val_loss: 1.6591 - val_acc: 0.5225\n",
      "Epoch 36/60\n",
      "8000/8000 [==============================] - 4s 453us/step - loss: 1.3096 - acc: 0.6003 - val_loss: 1.6381 - val_acc: 0.5410\n",
      "Epoch 37/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 1.2849 - acc: 0.6055 - val_loss: 1.6516 - val_acc: 0.5205\n",
      "Epoch 38/60\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 1.2699 - acc: 0.6144 - val_loss: 1.6540 - val_acc: 0.5340\n",
      "Epoch 39/60\n",
      "8000/8000 [==============================] - 4s 450us/step - loss: 1.2619 - acc: 0.6121 - val_loss: 1.6855 - val_acc: 0.5250\n",
      "Epoch 40/60\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 1.2620 - acc: 0.6066 - val_loss: 1.6578 - val_acc: 0.5265\n",
      "Epoch 41/60\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 1.2595 - acc: 0.6132 - val_loss: 1.7100 - val_acc: 0.5190\n",
      "Epoch 42/60\n",
      "8000/8000 [==============================] - 4s 450us/step - loss: 1.2532 - acc: 0.6199 - val_loss: 1.5936 - val_acc: 0.5530\n",
      "Epoch 43/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 1.2436 - acc: 0.6136 - val_loss: 1.6452 - val_acc: 0.5480\n",
      "Epoch 44/60\n",
      "8000/8000 [==============================] - 4s 451us/step - loss: 1.2473 - acc: 0.6196 - val_loss: 1.6602 - val_acc: 0.5415\n",
      "Epoch 45/60\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 1.2366 - acc: 0.6194 - val_loss: 1.6159 - val_acc: 0.5455\n",
      "Epoch 46/60\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 1.2135 - acc: 0.6284 - val_loss: 1.6312 - val_acc: 0.5420\n",
      "Epoch 47/60\n",
      "2512/8000 [========>.....................] - ETA: 2s - loss: 1.1866 - acc: 0.6413"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, validation_split=0.2, epochs=60, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1 = model.evaluate(X, y, verbose=0)\n",
    "print(\"Test Loss: %.2f%%\" % (scores1[0]*100))\n",
    "print(\"Test Accuracy: %.2f%%\" % (scores1[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, 4)\n",
    "f.subplots_adjust(hspace=0.5)\n",
    "\n",
    "for i in range(4):\n",
    "    axarr[0][i].imshow(np.reshape(X[i],(100,100)), cmap='hot', interpolation='nearest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
